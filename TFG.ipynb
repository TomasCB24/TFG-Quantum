{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "22eca57e",
   "metadata": {},
   "source": [
    "# TFG Tomás Camero"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "037836f7",
   "metadata": {},
   "source": [
    "En este fichero de investigacíon, se pretende trabajar y experimentación con modelos de aprendizaje automáticos cuánticos, a la vez que se compara con los clásicos. Para ello, se ha realizado una clasificación multiclase de tres números del conjunto de datos MNIST, del cual se han elegido el 3, 4 y 5. El motivo de esta eleccion de solo tres números no es mas que debido a los tiempos de entrenamiento y la poca experiencia en este sector. A continuación se presenta un indice con cada modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5811188",
   "metadata": {},
   "source": [
    "Para probar cada modelo, antes de redirigirse con el índice, es necesario ejecutar los imports globales y las variables globales. Después de eso, solo es ejecutar paso a paso cada modelo, desde el inicio hasta el final. \n",
    "\n",
    "IMPORTANTE: Debido a diferencias entre Qiskit y TensorFlow Quantum en los imports, es posible que si ejecutas Qiskit primero y luego intentas ejecutar TFQ, de problemas. Para solucionar esto, solo tienes que volver a ejecutar los imports globales y ejecutar TFQ de nuevo. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ece88be8",
   "metadata": {},
   "source": [
    "* [MLP](#MLP)\n",
    "    * [Inicialización de variables](#Inicialización)\n",
    "    * [Búsqueda de hiperparámetros](#Búsqueda)\n",
    "    * [Entrenamiento](#Entrenamiento)\n",
    "    * [Resultados](#Resultados)\n",
    "    * [Algunas gráficas](#Gráficas)\n",
    "* [Keras](#Keras)\n",
    "    * [Inicialización de variables](#Inicialización2)\n",
    "    * [Creación del modelo](#Modelo2)\n",
    "    * [Entrenamiento](#Entrenamiento2)\n",
    "    * [Resultados](#Resultados2)\n",
    "* [TensorFlow Quantum](#TensorFlow)\n",
    "    * [Inicialización de variables](#Inicialización3)\n",
    "    * [Clases](#Clases)\n",
    "    * [Creación del modelo híbrido](#Modelo3)\n",
    "    * [Entrenamiento](#Entrenamiento3)\n",
    "    * [Resultados](#Resultados3)\n",
    "* [Qiskit](#qiskit)\n",
    "    * [Inicialización de variables](#Inicialización4)\n",
    "    * [Funciones necesarias](#Funciones4)\n",
    "    * [Creación de la red híbrido](#Modelo4)\n",
    "    * [Entrenamiento](#Entrenamiento4)\n",
    "    * [Resultados](#Resultados4)\n",
    "* [Comparaciones](#comparaciones)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71e78516",
   "metadata": {},
   "source": [
    "# Imports Globales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "577e6a09",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import multiprocessing as mp\n",
    "from matplotlib.patches import Wedge, Circle\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import time as time\n",
    "import seaborn\n",
    "import cProfile\n",
    "from io import StringIO\n",
    "import pstats\n",
    "import psutil\n",
    "import threading\n",
    "import chart_studio.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "from plotly import tools\n",
    "from plotly.offline import init_notebook_mode, iplot\n",
    "import os\n",
    "import random\n",
    "from keras.datasets import mnist\n",
    "from sklearn import metrics\n",
    "from skimage.transform import resize\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "091d0ccc",
   "metadata": {},
   "source": [
    "# Variables Globales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1c4655a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cores = psutil.cpu_count()\n",
    "init_notebook_mode(connected=True)\n",
    "random_seed = 122230\n",
    "#random_seed = random.randint(1,1000000)\n",
    "#print(random_seed)\n",
    "os.environ['PYTHONHASHSEED'] = str(random_seed)\n",
    "random.seed(random_seed)\n",
    "np.random.seed(random_seed)\n",
    "num_epochs = 20 \n",
    "batch_size = 16 \n",
    "num_classes = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f34dc7e",
   "metadata": {},
   "source": [
    "# MLP<a class=\"anchor\" id=\"MLP\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e12a668",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets, metrics\n",
    "from sklearn.experimental import enable_halving_search_cv \n",
    "from sklearn.model_selection import HalvingGridSearchCV\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fda7c64",
   "metadata": {},
   "source": [
    "## 1. Inicialización de variables <a class=\"anchor\" id=\"Inicialización\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91800f93",
   "metadata": {},
   "outputs": [],
   "source": [
    "cpu_percent_list_train_mlp = []\n",
    "memory_usage_list_train_mlp= []\n",
    "cpu_percent_list_test_mlp= []\n",
    "memory_usage_list_test_mlp= []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e13be0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_x, train_y), (test_x, test_y) = mnist.load_data()\n",
    "\n",
    "train_x = train_x.reshape(60000, 784)\n",
    "test_x = test_x.reshape(10000, 784)\n",
    "\n",
    "indices_train = np.where((train_y == 3) | (train_y == 4) | (train_y == 5))\n",
    "x_train_filtered = train_x[indices_train]\n",
    "y_train_filtered = train_y[indices_train]\n",
    "\n",
    "\n",
    "indices_test = np.where((test_y == 3) | (test_y == 4) | (test_y == 5))\n",
    "x_test_filtered = test_x[indices_test]\n",
    "y_test_filtered = test_y[indices_test]\n",
    "\n",
    "\n",
    "train_y = y_train_filtered\n",
    "test_y = y_test_filtered\n",
    "\n",
    "train_x = np.array([resize(image, (4, 4)) for image in x_train_filtered])\n",
    "test_x = np.array([resize(image, (4, 4)) for image in x_test_filtered])\n",
    "\n",
    "train_x = train_x.reshape(train_x.shape[0], -1)\n",
    "test_x = test_x.reshape(test_x.shape[0], -1)\n",
    "\n",
    "train_x = train_x.astype('float32')\n",
    "test_x = test_x.astype('float32')\n",
    "train_x /= 255\n",
    "test_x /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a8461ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lists_cpu_and_ram_mlp_train():\n",
    "    global running\n",
    "    running = True\n",
    "\n",
    "    currentProcess = psutil.Process()\n",
    "    while running:\n",
    "        cpu_percent_list_train_mlp.append(currentProcess.cpu_percent(interval=1)/cores)\n",
    "        memory_usage_list_train_mlp.append(currentProcess.memory_percent())\n",
    "        \n",
    "def start_mlp_train():\n",
    "    global t\n",
    "\n",
    "    # create thread and start it\n",
    "    t = threading.Thread(target=lists_cpu_and_ram_mlp_train)\n",
    "    t.start()\n",
    "\n",
    "def stop_mlp_train():\n",
    "    global running\n",
    "    global t\n",
    "\n",
    "    # use `running` to stop loop in thread so thread will end\n",
    "    running = False\n",
    "\n",
    "    # wait for thread's end\n",
    "    t.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42174f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lists_cpu_and_ram_mlp_test():\n",
    "    global running\n",
    "    running = True\n",
    "    currentProcess = psutil.Process()\n",
    "\n",
    "    while running:\n",
    "        cpu_percent_list_test_mlp.append(currentProcess.cpu_percent(interval=1)/cores)\n",
    "        memory_usage_list_test_mlp.append(currentProcess.memory_percent())\n",
    "        \n",
    "def start_mlp_test():\n",
    "    global t\n",
    "    t = threading.Thread(target=lists_cpu_and_ram_mlp_test)\n",
    "    t.start()\n",
    "\n",
    "def stop_mlp_test():\n",
    "    global running\n",
    "    global t\n",
    "    running = False\n",
    "\n",
    "    t.join()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fb3fcc3",
   "metadata": {},
   "source": [
    "## 2. Funcion para buscar los mejores hiperparámetros <a class=\"anchor\" id=\"Búsqueda\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8edbc671",
   "metadata": {},
   "outputs": [],
   "source": [
    "def busqueda_de_atributos_mlp(modelo):\n",
    "    scoring = 'accuracy'\n",
    "    param_grid = {\n",
    "        'hidden_layer_sizes': [(50,), (100,), (50, 50), (100, 100), (50, 100), (100, 50), \n",
    "                               (50, 50, 50), (100, 100, 100), (50, 100, 50), (100, 50, 100),\n",
    "                               (50, 100, 50, 100), (100, 50, 100, 50)],\n",
    "        'activation': ['identity', 'logistic', 'tanh', 'relu'],\n",
    "        'solver': ['lbfgs', 'sgd', 'adam'],\n",
    "        'alpha': [0.00001, 0.0001, 0.001, 0.01, 0.1],\n",
    "        'learning_rate': ['constant', 'invscaling', 'adaptive'],\n",
    "        'max_iter': [15000,20000,25000]\n",
    "    }\n",
    "    \n",
    "    grid_search_mlp = HalvingGridSearchCV(estimator=modelo, param_grid=param_grid, scoring=scoring, cv=10)\n",
    "    grid_search_mlp.fit(train_x, train_y)\n",
    "\n",
    "    return [grid_search_mlp.best_estimator_,grid_search_mlp.best_params_]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8ee2ad7",
   "metadata": {},
   "source": [
    "## 3. Entrenamiento <a class=\"anchor\" id=\"Entrenamiento\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d993663",
   "metadata": {},
   "outputs": [],
   "source": [
    "def entrenamientoyresultados_mlp(modelo):\n",
    "    \n",
    "    clf_mlp = modelo\n",
    "    #Empezamos a contar el tiempo de entrenamiento\n",
    "    startTrainingTime_mlp = time.time()\n",
    "    \n",
    "    # Entrenamiento\n",
    "    start_mlp_train()\n",
    "    try:\n",
    "        clf_mlp.fit(train_x, train_y)\n",
    "    finally:\n",
    "        stop_mlp_train()\n",
    "\n",
    "\n",
    "    #Terminamos de contar el tiempo de entrenamiento\n",
    "    endTrainingTime_mlp = time.time()\n",
    "\n",
    "    #Calculamos el tiempo de entrenamiento\n",
    "    trainingTime_mlp = endTrainingTime_mlp - startTrainingTime_mlp  \n",
    "\n",
    "    validResults_mlp = 0\n",
    "\n",
    "    #Empezamos a contar el tiempo de testeo\n",
    "    \n",
    "    startTestingTime_mlp = time.time()\n",
    "    \n",
    "    start_mlp_test()\n",
    "    try:\n",
    "        \n",
    "        predicted_mlp = clf_mlp.predict(test_x)\n",
    "        precision_mlp = metrics.accuracy_score(test_y, predicted_mlp)\n",
    "        \n",
    "    finally:\n",
    "        stop_mlp_test()\n",
    "    \n",
    "    #Terminamos de contar el tiempo de testeo\n",
    "    endTestingTime_mlp = time.time()\n",
    "\n",
    "    #Calculamos el tiempo de testeo\n",
    "    testingTime_mlp = endTestingTime_mlp - startTestingTime_mlp  # Calculation of testing time\n",
    "    \n",
    "    #precision_mlp = round((validResults_mlp / testingSamples) * 100, 2)\n",
    "    \n",
    "    return precision_mlp*100,trainingTime_mlp, testingTime_mlp,clf_mlp,predicted_mlp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6cb3ba1",
   "metadata": {},
   "source": [
    "## 4. Resultados <a class=\"anchor\" id=\"Resultados2\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9eec532",
   "metadata": {},
   "outputs": [],
   "source": [
    "#parametros_mlp = busqueda_de_atributos_mlp(MLPClassifier())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84bb0974",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(parametros_mlp[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4dc1ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(parametros_mlp[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52aade9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo_mlp = MLPClassifier(activation='identity', alpha=0.001, hidden_layer_sizes=(100,), learning_rate='constant', max_iter=25000, solver='adam')\n",
    "resultados_mlp = entrenamientoyresultados_mlp(modelo_mlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "726e88ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(\"Resultados con parametros: \" + str(modelo[1]))\n",
    "print(\"-------------------------------\")\n",
    "#print(\"Muestras de entrenamiento: \", trainingSamples)\n",
    "print(\"Tiempo de entrenamiento: \", round(resultados_mlp[1], 2), \" s\")\n",
    "#print(\"Muestras de testeo: \", testingSamples)\n",
    "print(\"Tiempo de testeo: \", round(resultados_mlp[2], 2), \" s\")\n",
    "print(\"Precisión: \", resultados_mlp[0], \"%\")\n",
    "print(\"-------------------------------\")\n",
    "print(\"Uso de CPU en entrenamiento: \", cpu_percent_list_train_mlp)\n",
    "print(\"-------------------------------\")\n",
    "print(\"Uso de CPU en test: \", cpu_percent_list_test_mlp)\n",
    "print(\"-------------------------------\")\n",
    "print(\"Uso de RAM en entrenamiento: \", memory_usage_list_train_mlp)\n",
    "print(\"-------------------------------\")\n",
    "print(\"Uso de RAM en test: \", memory_usage_list_test_mlp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2c18f4c",
   "metadata": {},
   "source": [
    "## 5. Algunas gráficas <a class=\"anchor\" id=\"Gráficas\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19eab7b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicion_mlp = resultados_mlp[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd5823ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = metrics.confusion_matrix(test_y, predicion_mlp)\n",
    "plt.figure(figsize=(10,10))\n",
    "seaborn.heatmap(cm, annot=True, linewidths=.25, square = True, cmap = 'Blues_r')\n",
    "plt.ylabel('Actual label');\n",
    "plt.xlabel('Predicted label');\n",
    "all_sample_title = 'Accuracy Score: {0}%'.format(resultados_mlp[0])\n",
    "plt.title(all_sample_title, size = 15);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a48b721",
   "metadata": {},
   "source": [
    "# Keras CNN<a class=\"anchor\" id=\"Keras\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c39221a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "import torch.nn.functional as F\n",
    "from torch import cat, no_grad, manual_seed\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "from keras.layers import Dense, Conv2D, Flatten,MaxPooling2D,BatchNormalization,Dropout\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7415f300",
   "metadata": {},
   "source": [
    "## 1.  Inicialización de variables <a class=\"anchor\" id=\"Inicialización2\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d38c2d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "cpu_percent_list_train_keras = []\n",
    "memory_usage_list_train_keras = []\n",
    "cpu_percent_list_test_keras = []\n",
    "memory_usage_list_test_keras = []\n",
    "cpu_percent_list_train_keras2 = []\n",
    "memory_usage_list_train_keras2 = []\n",
    "cpu_percent_list_test_keras2 = []\n",
    "memory_usage_list_test_keras2 = []\n",
    "tf.random.set_seed(random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18964986",
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_x, train_y), (test_x, test_y) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9caec65",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lists_cpu_and_ram_keras_train():\n",
    "    global running\n",
    "    running = True\n",
    "\n",
    "    currentProcess = psutil.Process()\n",
    "    while running:\n",
    "        cpu_percent_list_train_keras.append(currentProcess.cpu_percent(interval=1)/cores)\n",
    "        memory_usage_list_train_keras.append(currentProcess.memory_percent())\n",
    "        \n",
    "def start_keras_train():\n",
    "    global t\n",
    "\n",
    "    t = threading.Thread(target=lists_cpu_and_ram_keras_train)\n",
    "    t.start()\n",
    "\n",
    "def stop_keras_train():\n",
    "    global running\n",
    "    global t\n",
    "\n",
    "    running = False\n",
    "\n",
    "    t.join()\n",
    "    \n",
    "def lists_cpu_and_ram_keras_test():\n",
    "    global running\n",
    "    running = True\n",
    "    currentProcess = psutil.Process()\n",
    "\n",
    "    while running:\n",
    "        cpu_percent_list_test_keras.append(currentProcess.cpu_percent(interval=1)/cores)\n",
    "        memory_usage_list_test_keras.append(currentProcess.memory_percent())\n",
    "        \n",
    "def start_keras_test():\n",
    "    global t\n",
    "\n",
    "    t = threading.Thread(target=lists_cpu_and_ram_keras_test)\n",
    "    t.start()\n",
    "\n",
    "def stop_keras_test():\n",
    "    global running\n",
    "    global t\n",
    "\n",
    "    running = False\n",
    "\n",
    "    t.join()\n",
    "    \n",
    "def lists_cpu_and_ram_keras_train2():\n",
    "    global running\n",
    "    running = True\n",
    "\n",
    "    currentProcess = psutil.Process()\n",
    "    while running:\n",
    "        cpu_percent_list_train_keras2.append(currentProcess.cpu_percent(interval=1)/cores)\n",
    "        memory_usage_list_train_keras2.append(currentProcess.memory_percent())\n",
    "        \n",
    "def start_keras_train2():\n",
    "    global t\n",
    "\n",
    "    t = threading.Thread(target=lists_cpu_and_ram_keras_train2)\n",
    "    t.start()\n",
    "\n",
    "def stop_keras_train2():\n",
    "    global running\n",
    "    global t\n",
    "\n",
    "    running = False\n",
    "\n",
    "    t.join()\n",
    "    \n",
    "def lists_cpu_and_ram_keras_test2():\n",
    "    global running\n",
    "    running = True\n",
    "    currentProcess = psutil.Process()\n",
    "\n",
    "    while running:\n",
    "        cpu_percent_list_test_keras2.append(currentProcess.cpu_percent(interval=1)/cores)\n",
    "        memory_usage_list_test_keras2.append(currentProcess.memory_percent())\n",
    "        \n",
    "def start_keras_test2():\n",
    "    global t\n",
    "\n",
    "    # create thread and start it\n",
    "    t = threading.Thread(target=lists_cpu_and_ram_keras_test2)\n",
    "    t.start()\n",
    "\n",
    "def stop_keras_test2():\n",
    "    global running\n",
    "    global t\n",
    "\n",
    "    running = False\n",
    "\n",
    "    t.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b85dda2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_indices = np.where((train_y == 3) | (train_y == 4) | (train_y == 5))\n",
    "x_train_filtered = train_x[train_indices]\n",
    "y_train_filtered = train_y[train_indices]\n",
    "test_indices = np.where((test_y == 3) | (test_y == 4) | (test_y == 5))\n",
    "x_test_filtered = test_x[test_indices]\n",
    "y_test_filtered = test_y[test_indices]\n",
    "\n",
    "y_train_filtered[y_train_filtered == 3] = 0\n",
    "y_train_filtered[y_train_filtered == 4] = 1\n",
    "y_train_filtered[y_train_filtered == 5] = 2\n",
    "y_test_filtered[y_test_filtered == 3] = 0\n",
    "y_test_filtered[y_test_filtered == 4] = 1\n",
    "y_test_filtered[y_test_filtered == 5] = 2\n",
    "\n",
    "train_y = y_train_filtered\n",
    "test_y = y_test_filtered\n",
    "\n",
    "train_x = np.array([resize(image, (4, 4)) for image in x_train_filtered])\n",
    "test_x = np.array([resize(image, (4, 4)) for image in x_test_filtered])\n",
    "\n",
    "train_x = np.expand_dims(train_x, axis=3)\n",
    "test_x = np.expand_dims(test_x, axis=3)\n",
    "\n",
    "train_x = train_x.astype('float32')\n",
    "test_x = test_x.astype('float32')\n",
    "train_x /= 255\n",
    "test_x /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2b1e4ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = to_categorical(train_y, num_classes)\n",
    "test_y = to_categorical(test_y, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "252bc776",
   "metadata": {},
   "source": [
    "## 2. Creacion de modelos <a class=\"anchor\" id=\"Modelo2\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d8f65e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_keras = Sequential()\n",
    "model_keras.add(Conv2D(input_shape=(4, 4, 1), filters=32, strides=(2, 2), padding='same', activation='relu', kernel_size=(3, 3)))\n",
    "model_keras.add(Conv2D(filters=64, strides=(2, 2), padding='same', activation='relu', kernel_size=(3, 3)))\n",
    "model_keras.add(Conv2D(filters=128, strides=(2, 2), padding='same', activation='relu', kernel_size=(3, 3)))\n",
    "model_keras.add(Flatten())\n",
    "model_keras.add(Dense(128, activation='relu'))\n",
    "model_keras.add(Dropout(0.5))\n",
    "model_keras.add(BatchNormalization())\n",
    "model_keras.add(Dense(32, activation='relu'))\n",
    "model_keras.add(Dense(3, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ac6c578",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_keras2 = Sequential()\n",
    "model_keras2.add(Conv2D(input_shape=(4, 4, 1), filters=32, strides=(2, 2), padding='same', activation='relu', kernel_size=(3, 3)))\n",
    "model_keras2.add(Conv2D(filters=64, strides=(2, 2), padding='same', activation='relu', kernel_size=(3, 3)))\n",
    "model_keras2.add(Conv2D(filters=128, strides=(2, 2), padding='same', activation='relu', kernel_size=(3, 3)))\n",
    "model_keras2.add(Flatten())\n",
    "model_keras2.add(Dense(128, activation='relu'))\n",
    "model_keras2.add(Dropout(0.5))\n",
    "model_keras2.add(BatchNormalization())\n",
    "model_keras2.add(Dense(32, activation='relu'))\n",
    "model_keras2.add(Dense(3, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be4cfb84",
   "metadata": {},
   "source": [
    "## 3. Entrenamiento <a class=\"anchor\" id=\"Entrenamiento2\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "299598f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "adam = Adam(learning_rate=0.0001) # ajustar la tasa de aprendizaje\n",
    "batch_size2 = 32\n",
    "model_keras.compile(optimizer=adam, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "start_keras_train()\n",
    "startTrainingTime_keras = time.time()\n",
    "history_keras = model_keras.fit(train_x, train_y, batch_size=batch_size2, epochs=num_epochs, validation_split=0.1)\n",
    "stop_keras_train()\n",
    "stopTrainingTime_keras = time.time()\n",
    "endTrainingTime_keras = stopTrainingTime_keras - startTrainingTime_keras "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ea324b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "adam = Adam(learning_rate=0.0001) # ajustar la tasa de aprendizaje\n",
    "model_keras2.compile(optimizer=adam, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "start_keras_train2()\n",
    "startTrainingTime_keras2 = time.time()\n",
    "history_keras2 = model_keras2.fit(train_x, train_y, batch_size=batch_size, epochs=num_epochs, validation_split=0.1)\n",
    "stop_keras_train2()\n",
    "stopTrainingTime_keras2 = time.time()\n",
    "endTrainingTime_keras2 = stopTrainingTime_keras2 - startTrainingTime_keras2 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28ab03b0",
   "metadata": {},
   "source": [
    "## 4. Resultados <a class=\"anchor\" id=\"Resultados\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2706e404",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_keras_test()\n",
    "starTestingTime_keras = time.time()\n",
    "score = model_keras.evaluate(test_x, test_y, verbose=0)\n",
    "stop_keras_test()\n",
    "stopTestingTime_keras = time.time()\n",
    "endTestingTime_keras = stopTestingTime_keras - starTestingTime_keras\n",
    "print(\"Test loss:\", score[0])\n",
    "print(\"Test accuracy:\", score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2f2fb92",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_keras_test2()\n",
    "starTestingTime_keras2 = time.time()\n",
    "score2 = model_keras2.evaluate(test_x, test_y, verbose=0)\n",
    "stop_keras_test2()\n",
    "stopTestingTime_keras2 = time.time()\n",
    "endTestingTime_keras2 = stopTestingTime_keras2 - starTestingTime_keras2\n",
    "print(\"Test loss:\", score2[0])\n",
    "print(\"Test accuracy:\", score2[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfd83e88",
   "metadata": {},
   "source": [
    "# TensorFlow Quantum <a class=\"anchor\" id=\"TensorFlow\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adf44291",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.layers import Dense, Conv2D, Flatten,MaxPooling2D,BatchNormalization,Dropout\n",
    "import tensorflow_quantum as tfq\n",
    "import cirq\n",
    "import sympy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbb2b17d",
   "metadata": {},
   "source": [
    "## 1.  Inicialización de variables <a class=\"anchor\" id=\"Inicialización3\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16dcde50",
   "metadata": {},
   "outputs": [],
   "source": [
    "cpu_percent_list_train_tfq = []\n",
    "memory_usage_list_train_tfq= []\n",
    "cpu_percent_list_test_tfq= []\n",
    "memory_usage_list_test_tfq= []\n",
    "tf.random.set_seed(random_seed)\n",
    "num_quantum_layers = 5  \n",
    "dense_layer_sizes = [64, 32] \n",
    "learning_rate = 0.0001  \n",
    "dropout_rate = 0.4  \n",
    "l1_reg = 0 \n",
    "l2_reg = 0  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8530179f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lists_cpu_and_ram_tfq_train():\n",
    "    global running\n",
    "    running = True\n",
    "\n",
    "    currentProcess = psutil.Process()\n",
    "    while running:\n",
    "        cpu_percent_list_train_tfq.append(currentProcess.cpu_percent(interval=1)/cores)\n",
    "        memory_usage_list_train_tfq.append(currentProcess.memory_percent())\n",
    "        \n",
    "def start_tfq_train():\n",
    "    global t\n",
    "\n",
    "    t = threading.Thread(target=lists_cpu_and_ram_tfq_train)\n",
    "    t.start()\n",
    "\n",
    "def stop_tfq_train():\n",
    "    global running\n",
    "    global t\n",
    "\n",
    "    running = False\n",
    "\n",
    "    t.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc753e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lists_cpu_and_ram_tfq_test():\n",
    "    global running\n",
    "    running = True\n",
    "    currentProcess = psutil.Process()\n",
    "\n",
    "    while running:\n",
    "        cpu_percent_list_test_tfq.append(currentProcess.cpu_percent(interval=1)/cores)\n",
    "        memory_usage_list_test_tfq.append(currentProcess.memory_percent())\n",
    "        \n",
    "def start_tfq_test():\n",
    "    global t\n",
    "\n",
    "    t = threading.Thread(target=lists_cpu_and_ram_tfq_test)\n",
    "    t.start()\n",
    "\n",
    "def stop_tfq_test():\n",
    "    global running\n",
    "    global t\n",
    "\n",
    "    running = False\n",
    "\n",
    "    t.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa2e7694",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train, x_test = x_train[..., np.newaxis], x_test[..., np.newaxis]\n",
    "\n",
    "train_filter = np.where((y_train == 3) | (y_train == 4) | (y_train == 5))\n",
    "test_filter = np.where((y_test == 3) | (y_test == 4) | (y_test == 5))\n",
    "x_train, y_train = x_train[train_filter], y_train[train_filter]\n",
    "x_test, y_test = x_test[test_filter], y_test[test_filter]\n",
    "\n",
    "x_train = x_train.astype(\"float32\") / 255\n",
    "x_test = x_test.astype(\"float32\") / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "483221cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_labels(y):\n",
    "    label_mapping = {3: 0, 4: 1, 5: 2}\n",
    "    return np.array([label_mapping[label] for label in y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd6a78f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_mapped = map_labels(y_train)\n",
    "y_test_mapped = map_labels(y_test)\n",
    "\n",
    "y_train = to_categorical(y_train_mapped, num_classes)\n",
    "y_test = to_categorical(y_test_mapped, num_classes)\n",
    "\n",
    "# Asegurar que el tamaño del conjunto de entrenamiento sea divisible por batch_size\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.2, random_state=42, stratify=y_train)\n",
    "num_train_batches = len(x_train) // batch_size\n",
    "num_val_batches = len(x_val) // batch_size\n",
    "\n",
    "x_train = x_train[:num_train_batches * batch_size]\n",
    "y_train = y_train[:num_train_batches * batch_size]\n",
    "\n",
    "x_val = x_val[:num_val_batches * batch_size]\n",
    "y_val = y_val[:num_val_batches * batch_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00506606",
   "metadata": {},
   "outputs": [],
   "source": [
    "def downsample(image, size=(4, 4)):\n",
    "    return tf.image.resize(image, size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66642365",
   "metadata": {},
   "outputs": [],
   "source": [
    "qubits = cirq.GridQubit.rect(4, 4)\n",
    "readout_operators = [cirq.Z(qubits[-1])]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34eb6505",
   "metadata": {},
   "source": [
    "## 2. Clases necesarias <a class=\"anchor\" id=\"Clases\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb7b6946",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data_circuit(x):\n",
    "    circuit = cirq.Circuit()\n",
    "    qubits = cirq.GridQubit.rect(4, 4)\n",
    "    \n",
    "    for i, pixel in enumerate(x.flatten()):\n",
    "        if pixel:\n",
    "            circuit.append(cirq.ry(np.pi * pixel).on(qubits[i]))\n",
    "            circuit.append(cirq.rz(np.pi * pixel).on(qubits[i]))\n",
    "    \n",
    "    return circuit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57da4d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_downsampled = np.array([downsample(x) for x in x_train])\n",
    "x_val_downsampled = np.array([downsample(x) for x in x_val])\n",
    "x_test_downsampled = np.array([downsample(x) for x in x_test])\n",
    "\n",
    "x_train_circuits = [generate_data_circuit(x) for x in x_train_downsampled]\n",
    "x_val_circuits = [generate_data_circuit(x) for x in x_val_downsampled]\n",
    "x_test_circuits = [generate_data_circuit(x) for x in x_test_downsampled]\n",
    "\n",
    "x_train_tfcirc = tfq.convert_to_tensor(x_train_circuits)\n",
    "x_val_tfcirc = tfq.convert_to_tensor(x_val_circuits)\n",
    "x_test_tfcirc = tfq.convert_to_tensor(x_test_circuits)\n",
    "\n",
    "# Asegurar que el tamaño del conjunto de prueba sea divisible por batch_size\n",
    "num_test_batches = len(x_test) // batch_size\n",
    "x_test_downsampled = x_test_downsampled[:num_test_batches * batch_size]\n",
    "x_test = x_test[:num_test_batches * batch_size]\n",
    "y_test = y_test[:num_test_batches * batch_size]\n",
    "\n",
    "x_test_tfcirc = tfq.convert_to_tensor(x_test_circuits[:num_test_batches * batch_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d92e426d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_model_circuit(qubits, num_layers):\n",
    "    model_circuit = cirq.Circuit()\n",
    "    symbols = sympy.symbols(f\"theta(0:{16 * num_layers})\")\n",
    "\n",
    "    for layer in range(num_layers):\n",
    "        for i in range(0, 16, 4):\n",
    "            model_circuit += cirq.Circuit(\n",
    "                cirq.rx(symbols[16 * layer + i]).on(qubits[i]),\n",
    "                cirq.rz(symbols[16 * layer + i + 1]).on(qubits[i + 1]),\n",
    "                cirq.rx(symbols[16 * layer + i + 2]).on(qubits[i + 2]),\n",
    "                cirq.rz(symbols[16 * layer + i + 3]).on(qubits[i + 3]),\n",
    "            )\n",
    "\n",
    "            model_circuit += cirq.Circuit(\n",
    "                cirq.CZ(qubits[i], qubits[i + 1]),\n",
    "                cirq.CZ(qubits[i + 1], qubits[i + 2]),\n",
    "                cirq.CZ(qubits[i + 2], qubits[i + 3]),\n",
    "            )\n",
    "\n",
    "        model_circuit += cirq.Circuit(\n",
    "            cirq.CZ(qubits[0], qubits[3]),\n",
    "            cirq.CZ(qubits[12], qubits[15]),\n",
    "        )\n",
    "\n",
    "    return model_circuit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcfca70f",
   "metadata": {},
   "source": [
    "## 3. Modelo Híbrido <a class=\"anchor\" id=\"Modelo3\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be22c486",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_circuit = generate_model_circuit(qubits, num_quantum_layers)\n",
    "quantum_model = tfq.layers.PQC(model_circuit, readout_operators)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf37fbe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entradas\n",
    "dense_input = tf.keras.Input(shape=(4, 4, 1), name='dense_input')\n",
    "quantum_input = tf.keras.Input(shape=(), dtype=tf.dtypes.string, name='quantum_input', batch_size=batch_size)\n",
    "\n",
    "# Circuito cuántico\n",
    "flatten = Flatten()(dense_input)\n",
    "dense_classic_1 = tf.keras.layers.Dense(32, activation=tf.keras.activations.relu)(flatten)\n",
    "dense_classic_2 = tf.keras.layers.Dense(16, activation=tf.keras.activations.relu)(dense_classic_1)\n",
    "reshaped = tf.keras.layers.Reshape((4, 4, 1))(dense_classic_2)\n",
    "downsampled = downsample(reshaped)\n",
    "\n",
    "# Aplanar la salida de downsampled\n",
    "flat_downsampled = Flatten()(downsampled)\n",
    "\n",
    "# Red cuántica\n",
    "quantum = quantum_model(quantum_input)\n",
    "\n",
    "# Modelo híbrido\n",
    "concat = tf.keras.layers.Concatenate()([flat_downsampled, quantum])\n",
    "dense_1 = tf.keras.layers.Dense(64, activation=tf.keras.activations.relu)(concat)\n",
    "dense_2 = tf.keras.layers.Dense(32, activation=tf.keras.activations.relu)(dense_1)\n",
    "dropout = tf.keras.layers.Dropout(dropout_rate)(dense_2)\n",
    "outputs = tf.keras.layers.Dense(num_classes, activation=tf.keras.activations.softmax)(dropout)\n",
    "\n",
    "# Crea el modelo\n",
    "model_tfq = tf.keras.Model(inputs=[dense_input, quantum_input], outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d1b6268",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_tfq = tf.keras.Model(inputs=[dense_input, quantum_input], outputs=outputs)\n",
    "model_tfq.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "                  loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "                  metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7330bafd",
   "metadata": {},
   "source": [
    "## 4. Entrenamiento  <a class=\"anchor\" id=\"Entrenamiento3\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65264aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_tfq_train()\n",
    "startTrainingTime_tfq = time.time()\n",
    "history_tfq = model_tfq.fit(\n",
    "    [x_train_downsampled, x_train_tfcirc], y_train, \n",
    "    batch_size=batch_size, epochs=num_epochs, verbose=1, \n",
    "    validation_data=([x_val_downsampled, x_val_tfcirc], y_val)\n",
    ")\n",
    "stop_tfq_train()\n",
    "stopTrainingTime_tfq = time.time()\n",
    "endTrainingTime_tfq = stopTrainingTime_tfq - startTrainingTime_tfq"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4ed5211",
   "metadata": {},
   "source": [
    "## 5. Resultados <a class=\"anchor\" id=\"Resultados3\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "523e234d",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_tfq_test()\n",
    "startTestingTime_tfq = time.time()\n",
    "test_loss, test_acc = model_tfq.evaluate([x_test_downsampled, x_test_tfcirc], y_test, batch_size=batch_size, verbose=1)\n",
    "stop_tfq_test()\n",
    "stopTestingTime_tfq = time.time()\n",
    "endTestingTime_tfq = stopTestingTime_tfq - startTestingTime_tfq\n",
    "print(\"Test accuracy:\", test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2fd2901",
   "metadata": {},
   "source": [
    "# Qiskit <a class=\"anchor\" id=\"qiskit\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f739a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import datasets, transforms\n",
    "from qiskit import QuantumCircuit\n",
    "from qiskit.utils import algorithm_globals\n",
    "from qiskit.circuit import Parameter\n",
    "from qiskit.circuit.library import RealAmplitudes, ZZFeatureMap\n",
    "from qiskit_machine_learning.neural_networks import SamplerQNN, EstimatorQNN\n",
    "from qiskit_machine_learning.connectors import TorchConnector\n",
    "import torch\n",
    "from torch.autograd import Function\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import qiskit\n",
    "from qiskit import transpile, assemble\n",
    "from qiskit.visualization import *\n",
    "from torch.nn import (\n",
    "    Module,\n",
    "    Conv2d,\n",
    "    Linear,\n",
    "    Dropout2d,\n",
    "    NLLLoss,\n",
    "    MaxPool2d,\n",
    "    Flatten,\n",
    "    Sequential,\n",
    "    ReLU,\n",
    ")\n",
    "from qiskit import QuantumCircuit, transpile, Aer, execute\n",
    "from qiskit.circuit import Parameter\n",
    "from qiskit.circuit.library import ZFeatureMap\n",
    "from qiskit.opflow import Z, StateFn\n",
    "from qiskit.utils import QuantumInstance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5266a29f",
   "metadata": {},
   "source": [
    "## 1.  Inicialización de variables <a class=\"anchor\" id=\"Inicialización4\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "066a8e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "cpu_percent_list_train_q= []\n",
    "memory_usage_list_train_q= []\n",
    "cpu_percent_list_test_q= []\n",
    "memory_usage_list_test_q= []\n",
    "n_samples = None\n",
    "\n",
    "def lists_cpu_and_ram_q_train():\n",
    "    global running\n",
    "    running = True\n",
    "\n",
    "    currentProcess = psutil.Process()\n",
    "    while running:\n",
    "        cpu_percent_list_train_q.append(currentProcess.cpu_percent(interval=1)/cores)\n",
    "        memory_usage_list_train_q.append(currentProcess.memory_percent())\n",
    "        \n",
    "def start_q_train():\n",
    "    global t\n",
    "\n",
    "    # create thread and start it\n",
    "    t = threading.Thread(target=lists_cpu_and_ram_q_train)\n",
    "    t.start()\n",
    "\n",
    "def stop_q_train():\n",
    "    global running\n",
    "    global t\n",
    "\n",
    "    # use `running` to stop loop in thread so thread will end\n",
    "    running = False\n",
    "\n",
    "    # wait for thread's end\n",
    "    t.join()\n",
    "    \n",
    "def lists_cpu_and_ram_q_test():\n",
    "    global running\n",
    "    running = True\n",
    "    currentProcess = psutil.Process()\n",
    "\n",
    "    while running:\n",
    "        cpu_percent_list_test_q.append(currentProcess.cpu_percent(interval=1)/cores)\n",
    "        memory_usage_list_test_q.append(currentProcess.memory_percent())\n",
    "        \n",
    "def start_q_test():\n",
    "    global t\n",
    "\n",
    "    # create thread and start it\n",
    "    t = threading.Thread(target=lists_cpu_and_ram_q_test)\n",
    "    t.start()\n",
    "\n",
    "def stop_q_test():\n",
    "    global running\n",
    "    global t\n",
    "\n",
    "    # use `running` to stop loop in thread so thread will end\n",
    "    running = False\n",
    "\n",
    "    # wait for thread's end\n",
    "    t.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a247f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = datasets.MNIST(root='./data', train=True, download=True,\n",
    "                         transform=transforms.Compose([transforms.ToTensor()]))\n",
    "\n",
    "idx_3 = np.where(X_train.targets == 3)[0][:n_samples]\n",
    "idx_6 = np.where(X_train.targets == 4)[0][:n_samples]\n",
    "idx_9 = np.where(X_train.targets == 5)[0][:n_samples]\n",
    "idx = np.concatenate((idx_3, idx_6, idx_9), axis=0)\n",
    "\n",
    "X_train.data = X_train.data[idx]\n",
    "X_train.targets = X_train.targets[idx]\n",
    "X_train.targets[X_train.targets == 3] = 0\n",
    "X_train.targets[X_train.targets == 4] = 1\n",
    "X_train.targets[X_train.targets == 5] = 2\n",
    "\n",
    "X_train.data = torch.nn.functional.interpolate(X_train.data.unsqueeze(1).float(), size=(4,4)).squeeze()\n",
    "\n",
    "X_train.data = X_train.data/255.0\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(X_train, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f68f2b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = datasets.MNIST(root='./data', train=False, download=True,\n",
    "                        transform=transforms.Compose([transforms.ToTensor()]))\n",
    "\n",
    "idy_3 = np.where(X_test.targets == 3)[0][:n_samples]\n",
    "idy_6 = np.where(X_test.targets == 4)[0][:n_samples]\n",
    "idy_9 = np.where(X_test.targets == 5)[0][:n_samples]\n",
    "idy = np.concatenate((idy_3, idy_6, idy_9), axis=0)\n",
    "\n",
    "X_test.data = X_test.data[idy]\n",
    "X_test.targets = X_test.targets[idy]\n",
    "X_test.targets[X_test.targets == 3] = 0\n",
    "X_test.targets[X_test.targets == 4] = 1\n",
    "X_test.targets[X_test.targets == 5] = 2\n",
    "\n",
    "X_test.data = torch.nn.functional.interpolate(X_test.data.unsqueeze(1).float(), size=(4,4)).squeeze()\n",
    "\n",
    "X_test.data = X_test.data/255.0\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(X_test, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "792a35ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.data = X_train.data.float() / 255.0\n",
    "y_train = X_train.targets\n",
    "\n",
    "X_test.data = X_test.data.float() / 255.0\n",
    "y_test = X_test.targets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52a10080",
   "metadata": {},
   "source": [
    "## 2. Funciones necesarias <a class=\"anchor\" id=\"Funciones4\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d5f8dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QuantumCircuit:\n",
    "    \n",
    "    def __init__(self, n_qubits, backend, shots):\n",
    "        self._circuit = qiskit.QuantumCircuit(n_qubits)\n",
    "        \n",
    "        all_qubits = [i for i in range(n_qubits)]\n",
    "        self.theta = qiskit.circuit.Parameter('theta')\n",
    "        \n",
    "        self._circuit.h(all_qubits)\n",
    "        self._circuit.barrier()\n",
    "        self._circuit.ry(self.theta, all_qubits)\n",
    "        \n",
    "        self._circuit.measure_all()\n",
    "\n",
    "        self.backend = backend\n",
    "        self.shots = shots\n",
    "\n",
    "    \n",
    "    def run(self, thetas):\n",
    "        t_qc = transpile(self._circuit,\n",
    "                         self.backend)\n",
    "        qobj = assemble(t_qc,\n",
    "                        shots=self.shots,\n",
    "                        parameter_binds=[{self.theta: theta} for theta in thetas])\n",
    "        job = self.backend.run(qobj)\n",
    "        result_list = job.result().get_counts()\n",
    "\n",
    "        # Combinar los resultados en un solo diccionario\n",
    "        result = {}\n",
    "        for r in result_list:\n",
    "            for k, v in r.items():\n",
    "                if k in result:\n",
    "                    result[k] += v\n",
    "                else:\n",
    "                    result[k] = v\n",
    "\n",
    "        counts = np.array(list(result.values()))\n",
    "        states = np.array([int(k, 2) for k in result.keys()]).astype(float)\n",
    "        probabilities = counts / (self.shots * len(thetas))\n",
    "        expectation = np.sum(states * probabilities)\n",
    "\n",
    "        return np.array([expectation])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb717743",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HybridFunction(Function):\n",
    "    \n",
    "    @staticmethod\n",
    "    def forward(ctx, inputs, quantum_circuit, shift):\n",
    "        ctx.shift = shift\n",
    "        ctx.quantum_circuit = quantum_circuit\n",
    "\n",
    "        expectation_z = []\n",
    "        for input in inputs:\n",
    "            expectation_z.append(ctx.quantum_circuit.run(input.tolist()))\n",
    "        result = torch.tensor(expectation_z, dtype=torch.float32)\n",
    "        \n",
    "        ctx.save_for_backward(inputs, result)\n",
    "        return result\n",
    "\n",
    "        \n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        input, expectation_z = ctx.saved_tensors\n",
    "        input_list = np.array(input.tolist())\n",
    "        \n",
    "        shift_right = input_list + np.ones(input_list.shape) * ctx.shift\n",
    "        shift_left = input_list - np.ones(input_list.shape) * ctx.shift\n",
    "        \n",
    "        gradients = np.zeros_like(input_list)\n",
    "        for i in range(len(input_list)):\n",
    "            expectation_right = ctx.quantum_circuit.run(shift_right[i])\n",
    "            expectation_left  = ctx.quantum_circuit.run(shift_left[i])\n",
    "\n",
    "            gradient = torch.tensor([expectation_right]) - torch.tensor([expectation_left])\n",
    "            gradients[i] = gradient\n",
    "\n",
    "        return torch.tensor([gradients]).float() * grad_output.float(), None, None\n",
    "\n",
    "class Hybrid(nn.Module):\n",
    "    \n",
    "    def __init__(self, backend, shots, shift):\n",
    "        super(Hybrid, self).__init__()\n",
    "        self.quantum_circuit = QuantumCircuit(16, backend, shots)\n",
    "        self.shift = shift\n",
    "        \n",
    "    def forward(self, input):\n",
    "        return HybridFunction.apply(input, self.quantum_circuit, self.shift)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36d54ae2",
   "metadata": {},
   "source": [
    "## 3. Red Híbrida <a class=\"anchor\" id=\"Modelo4\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cee54286",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 64, kernel_size=4, padding=0)\n",
    "        self.dropout = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(64, 256)\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        self.fc3 = nn.Linear(128, 4)  \n",
    "        self.hybrid = Hybrid(qiskit.Aer.get_backend('qasm_simulator'), 100, np.pi / 2)\n",
    "        self.fc4 = nn.Linear(1, 3) \n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = torch.flatten(x, start_dim=1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        x = self.hybrid(x)  # Utiliza solo una capa cuántica en lugar de varias\n",
    "        x = self.fc4(x)  # Agrega la capa lineal adicional después de la capa cuántica\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1924540",
   "metadata": {},
   "source": [
    "## 4. Entrenamiento <a class=\"anchor\" id=\"Entrenamiento4\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cf5d39c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model_q = Net()\n",
    "optimizer = optim.Adam(model_q.parameters(), lr=0.001)\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "\n",
    "epochs = 20\n",
    "loss_list = []\n",
    "\n",
    "start_q_train()\n",
    "startTrainingTime_q = time.time()\n",
    "model_q.train()\n",
    "for epoch in range(epochs):\n",
    "    total_loss = []\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "  \n",
    "        output = model_q(data)\n",
    "        loss = loss_func(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss.append(loss.item())\n",
    "    loss_list.append(sum(total_loss)/len(total_loss))\n",
    "    print('Training [{:.0f}%]\\tLoss: {:.4f}'.format(\n",
    "        100. * (epoch + 1) / epochs, loss_list[-1]))\n",
    "\n",
    "stop_q_train()\n",
    "stopTrainingTime_q = time.time()\n",
    "endTrainingTime_q = stopTrainingTime_q - startTrainingTime_q"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9620309",
   "metadata": {},
   "source": [
    "## 5. Resultados <a class=\"anchor\" id=\"Resultados4\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbd65de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_q.eval()\n",
    "start_q_test()\n",
    "startTestingTime_q = time.time()\n",
    "with torch.no_grad():\n",
    "    \n",
    "    correct = 0\n",
    "    for batch_idx, (data, target) in enumerate(test_loader):\n",
    "        output = model_q(data)\n",
    "        \n",
    "        pred = output.argmax(dim=1, keepdim=True)\n",
    "        correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "        \n",
    "        loss = loss_func(output, target)\n",
    "        total_loss.append(loss.item())\n",
    "        accuracy = correct / len(test_loader) * 100 / batch_size\n",
    "        \n",
    "    print('Performance on test data:\\n\\tLoss: {:.4f}\\n\\tAccuracy: {:.1f}%'.format(\n",
    "        sum(total_loss) / len(total_loss),\n",
    "        correct / len(test_loader) * 100 / batch_size)\n",
    "        )\n",
    "    \n",
    "stop_q_test()\n",
    "stopTestingTime_q = time.time()\n",
    "endTestingTime_q = stopTestingTime_q - startTestingTime_q"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df3951c5",
   "metadata": {},
   "source": [
    "# Comparaciones <a class=\"anchor\" id=\"comparaciones\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c065e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_classifiers = ['MLP','Keras','Keras2','TFQ','Qiskit']\n",
    "val_scores = [resultados_mlp[0], score[1]*100,score2[1]*100,test_acc*100,accuracy]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbbe5bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "trace1 = go.Scatter(x = list_classifiers, y = val_scores,\n",
    "                   name=\"Validation\", text = list_classifiers)\n",
    "\n",
    "data = [trace1]\n",
    "\n",
    "layout = dict(title = \"Validation and Submission Scores\", \n",
    "              xaxis=dict(ticklen=10, zeroline= False),\n",
    "              yaxis=dict(title = \"Accuracy\", side='left', ticklen=10,),                                  \n",
    "              legend=dict(orientation=\"v\", x=1.05, y=1.0),\n",
    "              autosize=False, width=750, height=500,\n",
    "              )\n",
    "\n",
    "fig = dict(data = data, layout = layout)\n",
    "iplot(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1265f38b",
   "metadata": {},
   "outputs": [],
   "source": [
    "grafica_precision = seaborn.barplot(x=[\"MPL\",\"Keras\",\"Keras2\",\"TFQ\",\"Qiskit\"],y=[resultados_mlp[0], score[1]*100,score2[1]*100,test_acc*100,accuracy])\n",
    "grafica_precision.figure.savefig(\"Precision_modelos.png\", dpi=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a43189e",
   "metadata": {},
   "outputs": [],
   "source": [
    "media_uso_cpu_entrenamiento_mlp = np.mean(cpu_percent_list_train_mlp)\n",
    "media_uso_cpu_entrenamiento_keras = np.mean(cpu_percent_list_train_keras)\n",
    "media_uso_cpu_entrenamiento_keras2 = np.mean(cpu_percent_list_train_keras2)\n",
    "media_uso_cpu_entrenamiento_tfq = np.mean(cpu_percent_list_train_tfq)\n",
    "media_uso_cpu_entrenamiento_q = np.mean(cpu_percent_list_train_q)\n",
    "\n",
    "media_uso_cpu_test_mlp = np.mean(cpu_percent_list_test_mlp)\n",
    "media_uso_cpu_test_keras = np.mean(cpu_percent_list_test_keras)\n",
    "media_uso_cpu_test_keras2 = np.mean(cpu_percent_list_test_keras2)\n",
    "media_uso_cpu_test_tfq = np.mean(cpu_percent_list_test_tfq)\n",
    "media_uso_cpu_test_q = np.mean(cpu_percent_list_test_q)\n",
    "\n",
    "nombres = ['Uso CPU entrenamiento MLP',\n",
    "           'Uso CPU entrenamiento Keras',\n",
    "           'Uso CPU entrenamiento Keras2',\n",
    "           'Uso CPU entrenamiento TFQ',\n",
    "           'Uso CPU entrenamiento Qiskit',\n",
    "           'Uso CPU test MLP',\n",
    "           'Uso CPU test keras',\n",
    "           'Uso CPU test Keras2',\n",
    "           'Uso CPU test TFQ',\n",
    "           'Uso CPU test Qiskit']\n",
    "\n",
    "porcentajes = [media_uso_cpu_entrenamiento_mlp,\n",
    "               media_uso_cpu_entrenamiento_keras,\n",
    "               media_uso_cpu_entrenamiento_keras2,\n",
    "               media_uso_cpu_entrenamiento_tfq,\n",
    "               media_uso_cpu_entrenamiento_q,\n",
    "               media_uso_cpu_test_mlp,\n",
    "               media_uso_cpu_test_keras,\n",
    "               media_uso_cpu_test_keras2, \n",
    "               media_uso_cpu_test_tfq,\n",
    "               media_uso_cpu_test_q]\n",
    "\n",
    "\n",
    "num_plots = len(porcentajes)\n",
    "num_cols = min(num_plots, 2)\n",
    "num_rows = (num_plots + num_cols - 1) // num_cols\n",
    "\n",
    "\n",
    "fig, axs = plt.subplots(num_rows, num_cols, figsize=(10, 10))\n",
    "for i, (porcentaje, nombre) in enumerate(zip(porcentajes, nombres)):\n",
    "    row = i // num_cols\n",
    "    col = i % num_cols\n",
    "    \n",
    "    restante = 100 - porcentaje\n",
    "    datos = [porcentaje, restante]\n",
    "    axs[row, col].pie(datos, colors=['blue', 'white'], startangle=90, counterclock=False, wedgeprops={'width': 0.5, 'edgecolor': 'white'})\n",
    "    axs[row, col].text(0, 0, f'{np.around(porcentaje, 1)}%', ha='center', va='center', fontsize=20)\n",
    "    axs[row, col].axis('equal')\n",
    "    axs[row, col].set_title(nombre)\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.savefig('Porcentajes_uso_cpu.png', dpi=400)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab51d94c",
   "metadata": {},
   "outputs": [],
   "source": [
    "media_uso_ram_entrenamiento_mlp = np.mean(memory_usage_list_train_mlp)\n",
    "media_uso_ram_entrenamiento_keras = np.mean(memory_usage_list_train_keras)\n",
    "media_uso_ram_entrenamiento_keras2 = np.mean(memory_usage_list_train_keras2)\n",
    "media_uso_ram_entrenamiento_tfq = np.mean(memory_usage_list_train_tfq)\n",
    "media_uso_ram_entrenamiento_q = np.mean(memory_usage_list_train_q)\n",
    "\n",
    "media_uso_ram_test_mlp = np.mean(memory_usage_list_test_mlp)\n",
    "media_uso_ram_test_keras = np.mean(memory_usage_list_test_keras)\n",
    "media_uso_ram_test_keras2 = np.mean(memory_usage_list_test_keras2)\n",
    "media_uso_ram_test_tfq = np.mean(memory_usage_list_test_tfq)\n",
    "media_uso_ram_test_q = np.mean(memory_usage_list_test_q)\n",
    "\n",
    "nombres = ['Uso RAM entrenamiento MLP',\n",
    "           'Uso RAM entrenamiento Keras',\n",
    "           'Uso RAM entrenamiento Keras2',\n",
    "           'Uso RAM entrenamiento TFG',\n",
    "           'Uso RAM entrenamiento Qiskit',\n",
    "           'Uso RAM test MLP',\n",
    "           'Uso RAM test Keras',\n",
    "           'Uso RAM test Keras2',\n",
    "           'Uso RAM test TFQ',\n",
    "           'Uso RAM test Qiskit']\n",
    "\n",
    "porcentajes = [media_uso_ram_entrenamiento_mlp, \n",
    "               media_uso_ram_entrenamiento_keras,\n",
    "               media_uso_ram_entrenamiento_keras2,\n",
    "               media_uso_ram_entrenamiento_tfq,\n",
    "               media_uso_ram_entrenamiento_q,\n",
    "               media_uso_ram_test_mlp,\n",
    "               media_uso_ram_test_keras,\n",
    "               media_uso_ram_test_keras2, \n",
    "               media_uso_ram_test_tfq,\n",
    "               media_uso_ram_test_q]\n",
    "\n",
    "\n",
    "num_plots = len(porcentajes)\n",
    "num_cols = min(num_plots, 2)\n",
    "num_rows = (num_plots + num_cols - 1) // num_cols\n",
    "\n",
    "\n",
    "fig, axs = plt.subplots(num_rows, num_cols, figsize=(10, 10))\n",
    "for i, (porcentaje, nombre) in enumerate(zip(porcentajes, nombres)):\n",
    "    row = i // num_cols\n",
    "    col = i % num_cols\n",
    "    restante = 100 - porcentaje\n",
    "    datos = [porcentaje, restante]\n",
    "    axs[row, col].pie(datos, colors=['blue', 'white'], startangle=90, counterclock=False, wedgeprops={'width': 0.5, 'edgecolor': 'white'})\n",
    "    axs[row, col].text(0, 0, f'{np.around(porcentaje, 1)}%', ha='center', va='center', fontsize=20)\n",
    "    axs[row, col].axis('equal')\n",
    "\n",
    "    axs[row, col].set_title(nombre)\n",
    "\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.savefig('Porcentajes_uso_ram.png', dpi=400)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2edc3379",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelos = [\"MPL\", \"Keras\", \"Keras2\", \"TFQ\", \"Qiskit\"]\n",
    "counts = [resultados_mlp[1], endTrainingTime_keras, endTrainingTime_keras2, endTrainingTime_tfq, endTrainingTime_q]\n",
    "\n",
    "fig = plt.figure(dpi=100, figsize=(10, 5))\n",
    "ax = fig.gca()\n",
    "seaborn.barplot(x=modelos, y=counts, ax=ax, orient=\"v\")\n",
    "ax.set_ylabel(\"Tiempo en segundos\")\n",
    "ax.set_xlabel(\"Modelo\")\n",
    "ax.set_title(f\"Tiempo de entrenamiento\")\n",
    "ax.set_yscale(\"log\")\n",
    "plt.savefig('Tiempo_entrenamiento.png', dpi=400)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1806691",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelos = [\"MPL\", \"Keras\",\"Keras2\",\"TFQ\",\"Qiskit\"]\n",
    "counts = [resultados_mlp[2],endTestingTime_keras,endTestingTime_keras2,endTestingTime_tfq,endTestingTime_q]\n",
    "fig = plt.figure(dpi=100, figsize=(10,5))\n",
    "ax = fig.gca()\n",
    "seaborn.barplot(x=modelos, y=counts, ax=ax, orient=\"v\")\n",
    "ax.set_ylabel(\"Tiempo en segundos\")\n",
    "ax.set_xlabel(\"Modelo\")\n",
    "ax.set_title(f\"Tiempo de entrenamiento\")\n",
    "ax.set_yscale(\"log\")\n",
    "plt.savefig('Tiempo_testeo.png', dpi=400)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
